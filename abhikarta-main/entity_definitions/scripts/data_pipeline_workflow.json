{
    "template_id": "script_data_pipeline_workflow",
    "name": "Data Processing Pipeline",
    "description": "A DAG workflow for data validation, transformation, and analysis",
    "entity_type": "workflow",
    "category": "data",
    "difficulty": "intermediate",
    "icon": "bi-diagram-3",
    "tags": [
        "workflow",
        "data",
        "pipeline",
        "processing"
    ],
    "use_count": 0,
    "script_content": "\"\"\"\nData Processing Pipeline - Python Script Mode\n==============================================\nA DAG workflow with custom node processors.\n\"\"\"\n\nfrom typing import Dict, List, Any, Optional\nfrom dataclasses import dataclass, field\nfrom enum import Enum\nfrom abc import ABC, abstractmethod\n\n\nclass NodeType(Enum):\n    INPUT = \"input\"\n    OUTPUT = \"output\"\n    VALIDATE = \"validate\"\n    TRANSFORM = \"transform\"\n    LLM = \"llm\"\n    AGGREGATE = \"aggregate\"\n\n\nclass ExecutionStatus(Enum):\n    PENDING = \"pending\"\n    RUNNING = \"running\"\n    COMPLETED = \"completed\"\n    FAILED = \"failed\"\n\n\n@dataclass\nclass NodeConfig:\n    node_id: str\n    name: str\n    node_type: NodeType\n    config: Dict[str, Any] = field(default_factory=dict)\n    \n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"node_id\": self.node_id,\n            \"name\": self.name,\n            \"node_type\": self.node_type.value,\n            \"config\": self.config\n        }\n\n\n@dataclass\nclass Edge:\n    source: str\n    target: str\n    \n    def to_dict(self) -> Dict[str, Any]:\n        return {\"source\": self.source, \"target\": self.target}\n\n\n@dataclass\nclass NodeResult:\n    node_id: str\n    status: ExecutionStatus\n    output: Any\n    error: Optional[str] = None\n    \n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"node_id\": self.node_id,\n            \"status\": self.status.value,\n            \"output\": str(self.output)[:200] if self.output else None,\n            \"error\": self.error\n        }\n\n\nclass NodeProcessor(ABC):\n    @abstractmethod\n    def process(self, input_data: Any, config: Dict) -> Any:\n        pass\n\n\nclass InputProcessor(NodeProcessor):\n    def process(self, input_data: Any, config: Dict) -> Any:\n        return input_data\n\n\nclass ValidateProcessor(NodeProcessor):\n    def process(self, input_data: Any, config: Dict) -> Any:\n        rules = config.get(\"rules\", [])\n        errors = []\n        for rule in rules:\n            if rule.get(\"type\") == \"required\":\n                field = rule.get(\"field\")\n                if isinstance(input_data, dict) and field not in input_data:\n                    errors.append(f\"Missing: {field}\")\n        return {\"data\": input_data, \"valid\": len(errors) == 0, \"errors\": errors}\n\n\nclass TransformProcessor(NodeProcessor):\n    def process(self, input_data: Any, config: Dict) -> Any:\n        result = input_data.copy() if isinstance(input_data, dict) else input_data\n        for t in config.get(\"transformations\", []):\n            if isinstance(result, dict) and t.get(\"field\") in result:\n                if t.get(\"type\") == \"uppercase\":\n                    result[t[\"field\"]] = str(result[t[\"field\"]]).upper()\n        return result\n\n\nclass LLMProcessor(NodeProcessor):\n    def process(self, input_data: Any, config: Dict) -> Any:\n        prompt = config.get(\"prompt\", \"Process: {input}\").format(input=str(input_data))\n        return {\"prompt\": prompt, \"response\": f\"Processed: {str(input_data)[:50]}\"}\n\n\nclass AggregateProcessor(NodeProcessor):\n    def process(self, input_data: Any, config: Dict) -> Any:\n        if isinstance(input_data, list):\n            return {\"count\": len(input_data), \"items\": input_data}\n        return {\"data\": input_data}\n\n\nclass OutputProcessor(NodeProcessor):\n    def process(self, input_data: Any, config: Dict) -> Any:\n        fmt = config.get(\"format\", \"json\")\n        return str(input_data) if fmt == \"text\" else input_data\n\n\nclass WorkflowEngine:\n    def __init__(self):\n        self.processors = {\n            NodeType.INPUT: InputProcessor(),\n            NodeType.VALIDATE: ValidateProcessor(),\n            NodeType.TRANSFORM: TransformProcessor(),\n            NodeType.LLM: LLMProcessor(),\n            NodeType.AGGREGATE: AggregateProcessor(),\n            NodeType.OUTPUT: OutputProcessor()\n        }\n        self.results: Dict[str, NodeResult] = {}\n    \n    def topological_sort(self, nodes: List[NodeConfig], edges: List[Edge]) -> List[str]:\n        in_degree = {n.node_id: 0 for n in nodes}\n        adj = {n.node_id: [] for n in nodes}\n        for edge in edges:\n            adj[edge.source].append(edge.target)\n            in_degree[edge.target] += 1\n        \n        queue = [n for n in in_degree if in_degree[n] == 0]\n        result = []\n        while queue:\n            node = queue.pop(0)\n            result.append(node)\n            for neighbor in adj[node]:\n                in_degree[neighbor] -= 1\n                if in_degree[neighbor] == 0:\n                    queue.append(neighbor)\n        return result\n    \n    def execute_node(self, node: NodeConfig, input_data: Any) -> NodeResult:\n        processor = self.processors.get(node.node_type)\n        if not processor:\n            return NodeResult(node.node_id, ExecutionStatus.FAILED, None, \"No processor\")\n        \n        try:\n            output = processor.process(input_data, node.config)\n            result = NodeResult(node.node_id, ExecutionStatus.COMPLETED, output)\n        except Exception as e:\n            result = NodeResult(node.node_id, ExecutionStatus.FAILED, None, str(e))\n        \n        self.results[node.node_id] = result\n        return result\n    \n    def get_input(self, node_id: str, edges: List[Edge]) -> Any:\n        inputs = []\n        for edge in edges:\n            if edge.target == node_id and edge.source in self.results:\n                inputs.append(self.results[edge.source].output)\n        return inputs[0] if len(inputs) == 1 else inputs if inputs else None\n    \n    def execute(self, nodes: List[NodeConfig], edges: List[Edge], initial_input: Any) -> Dict:\n        self.results = {}\n        order = self.topological_sort(nodes, edges)\n        nodes_map = {n.node_id: n for n in nodes}\n        \n        for node_id in order:\n            node = nodes_map[node_id]\n            input_data = initial_input if node.node_type == NodeType.INPUT else self.get_input(node_id, edges)\n            self.execute_node(node, input_data)\n        \n        output_result = None\n        for node in nodes:\n            if node.node_type == NodeType.OUTPUT:\n                output_result = self.results.get(node.node_id)\n        \n        return {\n            \"success\": all(r.status == ExecutionStatus.COMPLETED for r in self.results.values()),\n            \"output\": output_result.output if output_result else None,\n            \"node_results\": [r.to_dict() for r in self.results.values()]\n        }\n\n\n# Define workflow\nnodes = [\n    NodeConfig(\"input\", \"Data Input\", NodeType.INPUT),\n    NodeConfig(\"validate\", \"Validate\", NodeType.VALIDATE, {\"rules\": [{\"type\": \"required\", \"field\": \"data\"}]}),\n    NodeConfig(\"transform\", \"Transform\", NodeType.TRANSFORM, {\"transformations\": []}),\n    NodeConfig(\"llm\", \"LLM Analysis\", NodeType.LLM, {\"prompt\": \"Analyze: {input}\"}),\n    NodeConfig(\"output\", \"Output\", NodeType.OUTPUT, {\"format\": \"json\"})\n]\n\nedges = [\n    Edge(\"input\", \"validate\"),\n    Edge(\"validate\", \"transform\"),\n    Edge(\"transform\", \"llm\"),\n    Edge(\"llm\", \"output\")\n]\n\nworkflow = {\n    \"name\": \"Data Processing Pipeline\",\n    \"description\": \"Validates, transforms, and analyzes data\",\n    \"workflow_type\": \"dag\",\n    \"version\": \"1.0.0\",\n    \"nodes\": [n.to_dict() for n in nodes],\n    \"edges\": [e.to_dict() for e in edges],\n    \"environment\": {\"timeout_seconds\": 300},\n    \"tags\": [\"data\", \"pipeline\", \"python-script\"],\n    \"category\": \"data\"\n}\n\n__export__ = workflow\n\nengine = WorkflowEngine()\n\ndef execute(input_data: Dict[str, Any]) -> Dict[str, Any]:\n    result = engine.execute(nodes, edges, input_data)\n    return {\n        \"success\": result[\"success\"],\n        \"response\": result[\"output\"],\n        \"result\": result\n    }\n\n\ndef validate() -> tuple:\n    if not workflow.get(\"nodes\"):\n        return False, \"Workflow must have nodes\"\n    return True, \"Workflow configuration is valid\"\n"
}